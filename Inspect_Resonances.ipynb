{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnI2mlDKplfqc4b6IZwLvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlperYildirim1/Pay-Attention-Later/blob/main/Inspect_Resonances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q x-transformers"
      ],
      "metadata": {
        "id": "SvLO5U3q_Q3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. SETUP & MODEL LOADING (FIXED)\n",
        "# ==========================================\n",
        "import os\n",
        "import sys\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# --- CRITICAL FIX: Download the Model Definition FIRST ---\n",
        "REPO_ID = \"Yujivus/PRISM-Molecule\"\n",
        "filename = \"modeling_prism_gated.py\"\n",
        "\n",
        "print(f\"‚¨áÔ∏è Downloading {filename} from Hugging Face...\")\n",
        "if not os.path.exists(filename):\n",
        "    hf_hub_download(repo_id=REPO_ID, filename=filename, local_dir=\".\", force_download=True)\n",
        "\n",
        "# Now that the file exists locally, we can import it\n",
        "sys.path.append(\".\") # Ensure current dir is in path\n",
        "from modeling_prism_gated import PRISMHybrid_RoPE\n",
        "\n",
        "# Continue with standard imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "D_MODEL = 512\n",
        "\n",
        "print(\"‚è≥ Downloading Weights & Config...\")\n",
        "if not os.path.exists(\"config.json\"):\n",
        "    hf_hub_download(repo_id=REPO_ID, filename=\"config.json\", local_dir=\".\")\n",
        "if not os.path.exists(\"pytorch_model.bin\"):\n",
        "    hf_hub_download(repo_id=REPO_ID, filename=\"pytorch_model.bin\", local_dir=\".\")\n",
        "\n",
        "with open(\"config.json\", \"r\") as f: config = json.load(f)\n",
        "tokenizer = AutoTokenizer.from_pretrained(REPO_ID)\n",
        "\n",
        "# Initialize Model\n",
        "model = PRISMHybrid_RoPE(\n",
        "    vocab_size=config['vocab_size'], d_model=config['d_model'],\n",
        "    num_encoder_layers=config['num_encoder_layers'], num_refining_layers=0,\n",
        "    num_decoder_layers=6, num_heads=8, dff=2048, max_length=128, dropout=0.0\n",
        ").to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(\"pytorch_model.bin\", map_location=DEVICE))\n",
        "model.eval()\n",
        "print(\"‚úÖ Model Loaded Successfully.\")"
      ],
      "metadata": {
        "id": "xy1HCL1GzAbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üß≠ Extended Phase Compass: Synonyms vs Antonyms vs Randoms\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 2. DEFINING THE CANDIDATE PAIRS\n",
        "# ==========================================\n",
        "# Master list of all candidates\n",
        "candidates_raw = [\n",
        "    # --- ORIGINAL LIST ---\n",
        "    (\"Euro\", \"Geld\", \"Synonym\"),\n",
        "    (\"Auto\", \"Wagen\", \"Synonym\"),\n",
        "    (\"schnell\", \"rasch\", \"Synonym\"),\n",
        "    (\"Stimme\", \"Wahl\", \"Synonym\"),\n",
        "    (\"Zeit\", \"Uhr\", \"Synonym\"),\n",
        "    (\"Start\", \"Beginn\", \"Synonym\"),\n",
        "    (\"Ende\", \"Schluss\", \"Synonym\"),\n",
        "    (\"Raum\", \"Platz\", \"Synonym\"),\n",
        "\n",
        "    # --- NEW GERMAN SYNONYMS ---\n",
        "    (\"Haus\", \"Heim\", \"Synonym\"),\n",
        "    (\"Boot\", \"Schiff\", \"Synonym\"),\n",
        "    (\"See\", \"Meer\", \"Synonym\"),\n",
        "    (\"Wald\", \"Forst\", \"Synonym\"),\n",
        "    (\"Weg\", \"Pfad\", \"Synonym\"),\n",
        "    (\"Berg\", \"Gipfel\", \"Synonym\"),\n",
        "    (\"Mund\", \"Maul\", \"Synonym\"),\n",
        "    (\"Pferd\", \"Ross\", \"Synonym\"),\n",
        "    (\"Hund\", \"Tier\", \"Synonym\"),\n",
        "    (\"Reise\", \"Fahrt\", \"Synonym\"),\n",
        "    (\"Angst\", \"Furcht\", \"Synonym\"),\n",
        "    (\"Mut\", \"Traute\", \"Synonym\"),\n",
        "    (\"Gl√ºck\", \"Dusel\", \"Synonym\"),\n",
        "    (\"Ding\", \"Sache\", \"Synonym\"),\n",
        "    (\"Welt\", \"Erde\", \"Synonym\"),\n",
        "    (\"Stadt\", \"Ort\", \"Synonym\"),\n",
        "    (\"Vater\", \"Papa\", \"Synonym\"),\n",
        "    (\"Mutter\", \"Mama\", \"Synonym\"),\n",
        "    (\"klug\", \"weise\", \"Synonym\"),\n",
        "    (\"klug\", \"schlau\", \"Synonym\"),\n",
        "    (\"sch√∂n\", \"h√ºbsch\", \"Synonym\"),\n",
        "    (\"klein\", \"winzig\", \"Synonym\"),\n",
        "    (\"stark\", \"fest\", \"Synonym\"),\n",
        "    (\"neu\", \"frisch\", \"Synonym\"),\n",
        "    (\"still\", \"leise\", \"Synonym\"),\n",
        "    (\"froh\", \"heiter\", \"Synonym\"),\n",
        "    (\"dunkel\", \"finster\", \"Synonym\"),\n",
        "    (\"kalt\", \"eisig\", \"Synonym\"),\n",
        "    (\"rennen\", \"laufen\", \"Synonym\"),\n",
        "    (\"reden\", \"sagen\", \"Synonym\"),\n",
        "    (\"sehen\", \"schauen\", \"Synonym\"),\n",
        "    (\"gehen\", \"wandern\", \"Synonym\"),\n",
        "    (\"essen\", \"speisen\", \"Synonym\"),\n",
        "\n",
        "    # --- NEW ANTONYMS (OPPOSITES) ---\n",
        "    (\"gut\", \"b√∂se\", \"Antonym\"),\n",
        "    (\"gro√ü\", \"klein\", \"Antonym\"),\n",
        "    (\"hei√ü\", \"kalt\", \"Antonym\"),\n",
        "    (\"Tag\", \"Nacht\", \"Antonym\"),\n",
        "    (\"hoch\", \"tief\", \"Antonym\"),\n",
        "    (\"jung\", \"alt\", \"Antonym\"),\n",
        "    (\"voll\", \"leer\", \"Antonym\"),\n",
        "    (\"Liebe\", \"Hass\", \"Antonym\"),\n",
        "    (\"Krieg\", \"Frieden\", \"Antonym\"),\n",
        "    (\"Licht\", \"Schatten\", \"Antonym\"),\n",
        "    (\"Mann\", \"Frau\", \"Antonym\"),\n",
        "    (\"Start\", \"Ziel\", \"Antonym\"),\n",
        "    (\"Frage\", \"Antwort\", \"Antonym\"),\n",
        "\n",
        "    # --- NEW RANDOM/UNRELATED ---\n",
        "    (\"Mond\", \"Tisch\", \"Random\"),\n",
        "    (\"Brot\", \"Wolke\", \"Random\"),\n",
        "    (\"Schuh\", \"Idee\", \"Random\"),\n",
        "    (\"Baum\", \"Zahn\", \"Random\"),\n",
        "    (\"Glas\", \"L√∂we\", \"Random\"),\n",
        "    (\"Buch\", \"Suppe\", \"Random\"),\n",
        "    (\"Wand\", \"Vogel\", \"Random\"),\n",
        "    (\"Gras\", \"Auto\", \"Random\"),\n",
        "    (\"Salz\", \"Musik\", \"Random\"),\n",
        "    (\"Dach\", \"Fisch\", \"Random\"),\n",
        "    (\"Stein\", \"Wort\", \"Random\"),\n",
        "    (\"Kopf\", \"Preis\", \"Random\"),\n",
        "    (\"Hand\", \"Woche\", \"Random\"),\n",
        "    (\"Euro\", \"Apfel\", \"Random\"),\n",
        "    (\"Auto\", \"Idee\", \"Random\"),\n",
        "    (\"schnell\", \"Haus\", \"Random\"),\n",
        "    (\"Zeit\", \"Fisch\", \"Random\"),\n",
        "    (\"Start\", \"Milch\", \"Random\"),\n",
        "    (\"Raum\", \"Laufen\", \"Random\")\n",
        "]\n",
        "\n",
        "# ==========================================\n",
        "# 3. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def is_single_token(word):\n",
        "    \"\"\"Check if word is 1 token in vocabulary.\"\"\"\n",
        "    ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "    return len(ids) == 1, ids[0] if len(ids) == 1 else None\n",
        "\n",
        "def calculate_coherence(id_a, id_b):\n",
        "    \"\"\"Extract phases and calculate Mean Resultant Length (R).\"\"\"\n",
        "    # 1. Get Weights (CPU)\n",
        "    w = model.harmonic_embedding.complex_embedding.weight.detach().cpu()\n",
        "\n",
        "    # 2. Form Complex Numbers (Real + i*Imag)\n",
        "    za = torch.complex(w[id_a, :D_MODEL], w[id_a, D_MODEL:])\n",
        "    zb = torch.complex(w[id_b, :D_MODEL], w[id_b, D_MODEL:])\n",
        "\n",
        "    # 3. Phase Difference (Angle between vectors)\n",
        "    diff = torch.angle(za) - torch.angle(zb)\n",
        "\n",
        "    # 4. Energy Weighting (Magnitude * Magnitude)\n",
        "    #    Stronger concepts contribute more to the \"Phase Compass\"\n",
        "    weights = torch.abs(za) * torch.abs(zb)\n",
        "\n",
        "    # 5. Convert to Numpy\n",
        "    diff_np = diff.numpy()\n",
        "    weights_np = weights.numpy()\n",
        "\n",
        "    # 6. Calculate Circular Mean (R)\n",
        "    #    R ranges from 0 (Random/Cancel) to 1 (Perfect Alignment)\n",
        "    weighted_complex_diffs = weights_np * np.exp(1j * diff_np)\n",
        "    mean_vector = np.sum(weighted_complex_diffs) / np.sum(weights_np)\n",
        "\n",
        "    return np.abs(mean_vector), np.angle(mean_vector), diff_np, weights_np\n",
        "\n",
        "# ==========================================\n",
        "# 4. EXECUTE ANALYSIS\n",
        "# ==========================================\n",
        "valid_pairs = []\n",
        "results = []\n",
        "\n",
        "print(f\"\\n{'Pair':<25} | {'Type':<10} | {'Status':<15} | {'R (Coherence)'}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for w1, w2, ptype in candidates_raw:\n",
        "    s1, id1 = is_single_token(w1)\n",
        "    s2, id2 = is_single_token(w2)\n",
        "\n",
        "    if s1 and s2:\n",
        "        R, angle, diffs, weights = calculate_coherence(id1, id2)\n",
        "        valid_pairs.append({\n",
        "            \"w1\": w1, \"w2\": w2, \"type\": ptype,\n",
        "            \"R\": R, \"angle\": angle, \"diffs\": diffs, \"weights\": weights\n",
        "        })\n",
        "        results.append({\"Pair\": f\"{w1}-{w2}\", \"Type\": ptype, \"R\": R})\n",
        "        print(f\"{w1}-{w2:<20} | {ptype:<10} | ‚úÖ Valid        | {R:.4f}\")\n",
        "    else:\n",
        "        # Just logging for info, skipped in analysis\n",
        "        pass\n",
        "        # print(f\"{w1}-{w2:<20} | {ptype:<10} | ‚ùå Multi-token  | -\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. STATISTICS\n",
        "# ==========================================\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nüìä AGGREGATE STATS (Mean Resultant Length R):\")\n",
        "print(df.groupby(\"Type\")[\"R\"].describe())\n",
        "\n",
        "# ==========================================\n",
        "# 6. VISUALIZATION (GRID 3x3)\n",
        "# ==========================================\n",
        "# Select Top 3 from each category to show clearest examples\n",
        "synonyms = sorted([p for p in valid_pairs if p[\"type\"] == \"Synonym\"], key=lambda x: x[\"R\"], reverse=True)[:3]\n",
        "antonyms = sorted([p for p in valid_pairs if p[\"type\"] == \"Antonym\"], key=lambda x: x[\"R\"], reverse=True)[:3]\n",
        "randoms  = sorted([p for p in valid_pairs if p[\"type\"] == \"Random\"],  key=lambda x: x[\"R\"], reverse=False)[:3] # Lowest R for randoms\n",
        "\n",
        "plot_list = synonyms + antonyms + randoms\n",
        "\n",
        "if len(plot_list) > 0:\n",
        "    fig = plt.figure(figsize=(15, 12))\n",
        "    fig.suptitle(\"Semantic Phase Compass: Synonyms vs Antonyms vs Randoms\", fontsize=16, y=0.98)\n",
        "\n",
        "    # Colors for categories\n",
        "    colors = {\"Synonym\": \"red\", \"Antonym\": \"purple\", \"Random\": \"blue\"}\n",
        "\n",
        "    for i, item in enumerate(plot_list):\n",
        "        ax = fig.add_subplot(3, 3, i+1, projection='polar')\n",
        "\n",
        "        ptype = item[\"type\"]\n",
        "        color = colors[ptype]\n",
        "\n",
        "        # Weighted Histogram of Phase Differences\n",
        "        ax.hist(item[\"diffs\"], bins=30, weights=item[\"weights\"], color=color, alpha=0.7, density=True)\n",
        "\n",
        "        # Mean Vector Arrow (The \"Compass Needle\")\n",
        "        # Length of arrow = R (Coherence Strength)\n",
        "        ax.annotate(\"\", xy=(item[\"angle\"], item[\"R\"]), xytext=(0,0),\n",
        "                    arrowprops=dict(facecolor='black', width=2, headwidth=10))\n",
        "\n",
        "        # Styling\n",
        "        ax.set_title(f\"{item['w1']} - {item['w2']}\\n{ptype}\\nR = {item['R']:.3f}\", fontsize=11)\n",
        "        ax.set_yticklabels([]) # Hide radial labels\n",
        "        ax.set_xticklabels([]) # Hide angular labels\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"phase_compass_extended.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(\"\\nüì∏ Saved plot to 'phase_compass_extended.png'\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not enough valid pairs to generate plot.\")"
      ],
      "metadata": {
        "id": "vmp0y5TYdTd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}